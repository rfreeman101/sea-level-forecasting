{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before i can perform analysis on any of the data i will need to clean all the raw .csv files. Some have been downloaded from HTML format, and almost all of them come from different sources, so they'll all need different cleaning steps.\n",
    "\n",
    "In order to perform timeseries analysis on them properly i'll also need to ensure that they have the same intervals and are across the same period (i.e. they have the same start and end dates to the samples). To make the data work with the most limiting dataset, the sample interval will need to be monthly, with the first sample being April 2002 and the most recent sample being November 2022. I have created a custom function that i'll use to convert each clean dataframe to this format.\n",
    "\n",
    "Once all the dataframes have been cleaned and have uniform length and intervals, i'll join them in to one dataset to perform my analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import datetime\n",
    "\n",
    "# Custom helper functions.\n",
    "import sys\n",
    "sys.path.append('../libraries')\n",
    "import cleaning_helper_functions as prep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV files to pandas dataframes.\n",
    "df_south_raw = pd.read_csv('../data/raw/S_seaice_extent_daily_v3.0.csv')\n",
    "df_north_raw = pd.read_csv('../data/raw/N_seaice_extent_daily_v3.0.csv')\n",
    "df_antarctica_ice_raw = pd.read_csv('../data/raw/antarctica_ice_sheet.csv')\n",
    "df_greenland_ice_raw = pd.read_csv('../data/raw/greeland_ice_sheet.csv')\n",
    "df_sea_level_raw = pd.read_csv('../data/raw/global_mean_sea_level.csv')\n",
    "df_sea_temp_raw = pd.read_csv('../data/raw/sea_temperature.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sea Ice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Inspection - South Sea Ice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE\n",
      "Rows: 14546 \t Columns: 6\n",
      "\n",
      "DATATYPES\n",
      "Columns: \n",
      "Year            object\n",
      " Month          object\n",
      " Day            object\n",
      "     Extent     object\n",
      "    Missing     object\n",
      " Source Data    object\n",
      "dtype: object\n",
      "Index: integer\n",
      "\n",
      "UNIQUE VALUES\n",
      "Year               47\n",
      " Month             13\n",
      " Day               32\n",
      "     Extent      9306\n",
      "    Missing         5\n",
      " Source Data    14546\n",
      "dtype: int64\n",
      "\n",
      "NULL VALUES\n",
      "Total null rows: 0\n",
      "Percentage null rows: 0.0%\n",
      "\n",
      "DUPLICATES\n",
      "Total duplicate rows: 0\n",
      "Percentage duplicate rows: 0.0%\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep.basic_eda(df_south_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Source Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YYYY</td>\n",
       "      <td>MM</td>\n",
       "      <td>DD</td>\n",
       "      <td>10^6 sq km</td>\n",
       "      <td>10^6 sq km</td>\n",
       "      <td>Source data product web sites: http://nsidc.o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1978</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>17.624</td>\n",
       "      <td>0.000</td>\n",
       "      <td>['/ecs/DP1/PM/NSIDC-0051.001/1978.10.26/nt_19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1978</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>17.803</td>\n",
       "      <td>0.000</td>\n",
       "      <td>['/ecs/DP1/PM/NSIDC-0051.001/1978.10.28/nt_19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1978</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>17.670</td>\n",
       "      <td>0.000</td>\n",
       "      <td>['/ecs/DP1/PM/NSIDC-0051.001/1978.10.30/nt_19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1978</td>\n",
       "      <td>11</td>\n",
       "      <td>01</td>\n",
       "      <td>17.527</td>\n",
       "      <td>0.000</td>\n",
       "      <td>['/ecs/DP1/PM/NSIDC-0051.001/1978.11.01/nt_19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Month   Day       Extent      Missing  \\\n",
       "0  YYYY      MM    DD   10^6 sq km   10^6 sq km   \n",
       "1  1978      10    26       17.624        0.000   \n",
       "2  1978      10    28       17.803        0.000   \n",
       "3  1978      10    30       17.670        0.000   \n",
       "4  1978      11    01       17.527        0.000   \n",
       "\n",
       "                                         Source Data  \n",
       "0   Source data product web sites: http://nsidc.o...  \n",
       "1   ['/ecs/DP1/PM/NSIDC-0051.001/1978.10.26/nt_19...  \n",
       "2   ['/ecs/DP1/PM/NSIDC-0051.001/1978.10.28/nt_19...  \n",
       "3   ['/ecs/DP1/PM/NSIDC-0051.001/1978.10.30/nt_19...  \n",
       "4   ['/ecs/DP1/PM/NSIDC-0051.001/1978.11.01/nt_19...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_south_raw.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Inspection - North Sea Ice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE\n",
      "Rows: 14546 \t Columns: 6\n",
      "\n",
      "DATATYPES\n",
      "Columns: \n",
      "Year            object\n",
      " Month          object\n",
      " Day            object\n",
      "     Extent     object\n",
      "    Missing     object\n",
      " Source Data    object\n",
      "dtype: object\n",
      "Index: integer\n",
      "\n",
      "UNIQUE VALUES\n",
      "Year               47\n",
      " Month             13\n",
      " Day               32\n",
      "     Extent      8079\n",
      "    Missing         2\n",
      " Source Data    14546\n",
      "dtype: int64\n",
      "\n",
      "NULL VALUES\n",
      "Total null rows: 0\n",
      "Percentage null rows: 0.0%\n",
      "\n",
      "DUPLICATES\n",
      "Total duplicate rows: 0\n",
      "Percentage duplicate rows: 0.0%\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep.basic_eda(df_north_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Source Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YYYY</td>\n",
       "      <td>MM</td>\n",
       "      <td>DD</td>\n",
       "      <td>10^6 sq km</td>\n",
       "      <td>10^6 sq km</td>\n",
       "      <td>Source data product web sites: http://nsidc.o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1978</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>10.231</td>\n",
       "      <td>0.000</td>\n",
       "      <td>['/ecs/DP1/PM/NSIDC-0051.001/1978.10.26/nt_19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1978</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>10.420</td>\n",
       "      <td>0.000</td>\n",
       "      <td>['/ecs/DP1/PM/NSIDC-0051.001/1978.10.28/nt_19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1978</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>10.557</td>\n",
       "      <td>0.000</td>\n",
       "      <td>['/ecs/DP1/PM/NSIDC-0051.001/1978.10.30/nt_19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1978</td>\n",
       "      <td>11</td>\n",
       "      <td>01</td>\n",
       "      <td>10.670</td>\n",
       "      <td>0.000</td>\n",
       "      <td>['/ecs/DP1/PM/NSIDC-0051.001/1978.11.01/nt_19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Month   Day       Extent      Missing  \\\n",
       "0  YYYY      MM    DD   10^6 sq km   10^6 sq km   \n",
       "1  1978      10    26       10.231        0.000   \n",
       "2  1978      10    28       10.420        0.000   \n",
       "3  1978      10    30       10.557        0.000   \n",
       "4  1978      11    01       10.670        0.000   \n",
       "\n",
       "                                         Source Data  \n",
       "0   Source data product web sites: http://nsidc.o...  \n",
       "1   ['/ecs/DP1/PM/NSIDC-0051.001/1978.10.26/nt_19...  \n",
       "2   ['/ecs/DP1/PM/NSIDC-0051.001/1978.10.28/nt_19...  \n",
       "3   ['/ecs/DP1/PM/NSIDC-0051.001/1978.10.30/nt_19...  \n",
       "4   ['/ecs/DP1/PM/NSIDC-0051.001/1978.11.01/nt_19...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_north_raw.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- All column headers except `Year` are formatted with trailing or leading whitespace characters.\n",
    "- Entries are made every two days to begin with, but every day by the end of the dataset.\n",
    "- No Null values or duplicate rows.\n",
    "- No duplicate columns.\n",
    "- First data entry is an extended description of the column.\n",
    "- All columns are set as object datatypes.\n",
    "- There are very few rows missing data in the `Missing` column, and it won't be required for my analysis.\n",
    "- The `Source Data` column just returns a list of links, so isn't helpful in my analysis.\n",
    "- Both datasets have the same features (size, datatypes, formatting etc.)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning - Sea Ice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As these two datasets are taken from the same source, and have the same layout etc. i will be able to define one function that carries out all the cleaning steps, and then enact that function on both datasets to speed up the cleaning process.\n",
    "\n",
    "I'll also combine the northern and southern hemisphere data in to a 'Total Sea Ice Extent' column to use for my analysis, as it will look at global mean sea level.\n",
    "\n",
    "Cleaning Steps:\n",
    "- Remove whitespace characters from column headers.\n",
    "- Extract information from and remove first row.\n",
    "- Concatenate `Year`, `Month` and `Day` to datetime `Date` column.\n",
    "- Set `Date` column as the index.\n",
    "- Drop the `Source Data`, `Missing`, `Year`, `Month` and `Day` columns.\n",
    "- Change `Extent` columns to `float` datatype.\n",
    "- Join the two datasets.\n",
    "- Standardise the reading frequency by including the missing days earlier in the dataset.\n",
    "- Interpolate any null values created by the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function \n",
    "def clean_sea_ice(df):\n",
    "    \"\"\"\n",
    "    Performs required cleaning steps on the sea ice dataframes.\n",
    "\n",
    "    Inputs:\n",
    "        - pandas Dataframe.\n",
    "    \"\"\"\n",
    "    # Remove whitespace characters from column headers.\n",
    "    for col in df.columns:\n",
    "        new_header = col.strip()\n",
    "        df.rename(columns={col:new_header}, inplace=True)\n",
    "\n",
    "    # Remove first row.\n",
    "    df.drop(index=df.index[0], axis=0, inplace=True)\n",
    "\n",
    "    # Create Date column from Year, Month and Day and set as index.\n",
    "    df['Date'] = pd.to_datetime(df[['Year','Month','Day']])\n",
    "    df.set_index('Date', inplace=True)\n",
    "\n",
    "    # Drop unrequired columns.\n",
    "    df.drop(['Year','Month','Day','Missing','Source Data'], axis=1, inplace=True)\n",
    "\n",
    "    # Set Extent datatype as float. \n",
    "    df[['Extent']] = df[['Extent']].astype(float)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input each dataframe in to the function.\n",
    "df_south_raw = clean_sea_ice(df_south_raw)\n",
    "df_north_raw = clean_sea_ice(df_north_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join datasets.\n",
    "df_sea_ice = df_south_raw.join(df_north_raw, lsuffix='_South', rsuffix='_North')\n",
    "\n",
    "# Reindex to include missing dates and interpolate new values.\n",
    "df_sea_ice = df_sea_ice.reindex(pd.date_range(df_sea_ice.index[0],df_sea_ice.index[-1]))\n",
    "df_sea_ice[['Extent_South','Extent_North']] = df_sea_ice[['Extent_South','Extent_North']].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample timeseries to required length.\n",
    "df_sea_ice_resampled = prep.resample_timeseries(df_sea_ice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create total column and drop original columns.\n",
    "df_sea_ice_resampled['global_sea_ice_extent'] = df_sea_ice_resampled['Extent_North'] + df_sea_ice_resampled['Extent_South']\n",
    "df_sea_ice_resampled.drop(['Extent_North','Extent_South'],axis=1,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review - Sea Ice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE\n",
      "Rows: 248 \t Columns: 1\n",
      "\n",
      "DATATYPES\n",
      "Columns: \n",
      "global_sea_ice_extent    float64\n",
      "dtype: object\n",
      "Index: datetime64\n",
      "\n",
      "UNIQUE VALUES\n",
      "global_sea_ice_extent    248\n",
      "dtype: int64\n",
      "\n",
      "NULL VALUES\n",
      "Total null rows: 0\n",
      "Percentage null rows: 0.0%\n",
      "\n",
      "DUPLICATES\n",
      "Total duplicate rows: 0\n",
      "Percentage duplicate rows: 0.0%\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep.basic_eda(df_sea_ice_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_sea_ice_extent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-04-30</th>\n",
       "      <td>20.627267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-31</th>\n",
       "      <td>22.482161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-06-30</th>\n",
       "      <td>23.959167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-07-31</th>\n",
       "      <td>24.688871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-08-31</th>\n",
       "      <td>23.665677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            global_sea_ice_extent\n",
       "2002-04-30              20.627267\n",
       "2002-05-31              22.482161\n",
       "2002-06-30              23.959167\n",
       "2002-07-31              24.688871\n",
       "2002-08-31              23.665677"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sea_ice_resampled.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ice Sheets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Inspection - Antarctica Ice Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE\n",
      "Rows: 245 \t Columns: 1\n",
      "\n",
      "DATATYPES\n",
      "Columns: \n",
      "HDR Antarctica Mass    object\n",
      "dtype: object\n",
      "Index: integer\n",
      "\n",
      "UNIQUE VALUES\n",
      "HDR Antarctica Mass    238\n",
      "dtype: int64\n",
      "\n",
      "NULL VALUES\n",
      "Total null rows: 0\n",
      "Percentage null rows: 0.0%\n",
      "\n",
      "DUPLICATES\n",
      "Total duplicate rows: 8\n",
      "Percentage duplicate rows: 3.27%\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep.basic_eda(df_antarctica_ice_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HDR Antarctica Mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HDR Data from the GRACE and GRACE-FO JPL RL06....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HDR This file contains values that are anomali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDR auspices of the NASA MEaSUREs program. The...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 HDR Antarctica Mass\n",
       "0                                                HDR\n",
       "1  HDR Data from the GRACE and GRACE-FO JPL RL06....\n",
       "2                                                HDR\n",
       "3  HDR This file contains values that are anomali...\n",
       "4  HDR auspices of the NASA MEaSUREs program. The..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_antarctica_ice_raw.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection - Greenland Ice Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE\n",
      "Rows: 245 \t Columns: 1\n",
      "\n",
      "DATATYPES\n",
      "Columns: \n",
      "HDR Greenland Mass    object\n",
      "dtype: object\n",
      "Index: integer\n",
      "\n",
      "UNIQUE VALUES\n",
      "HDR Greenland Mass    238\n",
      "dtype: int64\n",
      "\n",
      "NULL VALUES\n",
      "Total null rows: 0\n",
      "Percentage null rows: 0.0%\n",
      "\n",
      "DUPLICATES\n",
      "Total duplicate rows: 8\n",
      "Percentage duplicate rows: 3.27%\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep.basic_eda(df_greenland_ice_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HDR Greenland Mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HDR Data from the GRACE and GRACE-FO JPL RL06....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HDR This file contains values that are anomali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDR auspices of the NASA MEaSUREs program. The...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  HDR Greenland Mass\n",
       "0                                                HDR\n",
       "1  HDR Data from the GRACE and GRACE-FO JPL RL06....\n",
       "2                                                HDR\n",
       "3  HDR This file contains values that are anomali...\n",
       "4  HDR auspices of the NASA MEaSUREs program. The..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_greenland_ice_raw.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the views above, as well as looking at the raw data file, the following observations can be made.\n",
    "\n",
    "Observations:\n",
    "- Several lines of comment text at the head of the file.\n",
    "- All data in one column.\n",
    "- No null values or duplicate rows or columns.\n",
    "- Date is given as a decimal.\n",
    "- `Mass_Gigatonnes_1_sigma_unc` will not be useful in my analysis.\n",
    "- All columns are object datatype."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning - Ice Sheets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the sea ice extent data, it looks like both datasets have the same layout and features. I'll therefore be able to define another function that i can feed both datasets through to clean them.\n",
    "\n",
    "Again, i'll also combine both columns in to a total column to use in my analysis going forwards.\n",
    "\n",
    "Cleaning Steps:\n",
    "- Remove all text at the head of the file.\n",
    "- Split the data in to multiple columns.\n",
    "- Rename columns.\n",
    "- Create `Date` column by converting `Date_Decimal` to datetime.\n",
    "- Set `Date` as index.\n",
    "- Drop `Mass_Gigatonnes_1_sigma_unc` and `Date_Decimal`.\n",
    "- Convert `Mass_Gigatonnes` to float.\n",
    "- Combine datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ice_sheet_cleaning(df):\n",
    "    # Drop all text rows and reset index.\n",
    "    df = df[df.iloc[:,0].str.startswith('HDR')==False].reset_index(drop=True)\n",
    "\n",
    "    # Split into columns based on one or more whitespace characters as delimiters.\n",
    "    df = df.iloc[:,0].str.split(' +',expand=True, regex=True) \n",
    "\n",
    "    # Rename columns.\n",
    "    df = df.rename({0:'Decimal_Date',1:'Mass_Gigatonnes',2:'Mass_Gigatonnes_1_sigma_unc'},axis='columns')\n",
    "\n",
    "    # Create date column from list of converted decimal dates and set as index.\n",
    "    df['Date'] = pd.to_datetime([prep.decimal_to_datetime(date) for date in df['Decimal_Date'].astype(float).tolist()]) \n",
    "    df.set_index('Date', inplace=True)\n",
    "\n",
    "    # Drop unrequired columns.\n",
    "    df.drop(['Decimal_Date','Mass_Gigatonnes_1_sigma_unc'], axis=1, inplace=True)\n",
    "\n",
    "    # Convert mass to float.\n",
    "    df['Mass_Gigatonnes'] = df['Mass_Gigatonnes'].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean datasets.\n",
    "df_greenland_ice_raw = ice_sheet_cleaning(df_greenland_ice_raw)\n",
    "df_antarctica_ice_raw = ice_sheet_cleaning(df_antarctica_ice_raw)\n",
    "\n",
    "# Join datasets.\n",
    "df_ice_sheets = df_greenland_ice_raw.join(df_antarctica_ice_raw, lsuffix='_Greenland', rsuffix='_Antarctica')\n",
    "\n",
    "# Reindex the dataframe to include the missing dates and interpolate new values.\n",
    "df_ice_sheets = df_ice_sheets.reindex(pd.date_range(df_ice_sheets.index[0],df_ice_sheets.index[-1]))\n",
    "df_ice_sheets[['Mass_Gigatonnes_Greenland','Mass_Gigatonnes_Antarctica']] = \\\n",
    "    df_ice_sheets[['Mass_Gigatonnes_Greenland','Mass_Gigatonnes_Antarctica']].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample timeseries to match required length.\n",
    "df_ice_sheets_resampled = prep.resample_timeseries(df_ice_sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ice_sheets_resampled['total_ice_sheet_mass_change'] = df_ice_sheets_resampled['Mass_Gigatonnes_Antarctica'] + df_ice_sheets_resampled['Mass_Gigatonnes_Greenland']\n",
    "df_ice_sheets_resampled.drop(['Mass_Gigatonnes_Antarctica','Mass_Gigatonnes_Greenland'],axis=1,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review - Ice Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE\n",
      "Rows: 248 \t Columns: 1\n",
      "\n",
      "DATATYPES\n",
      "Columns: \n",
      "total_ice_sheet_mass_change    float64\n",
      "dtype: object\n",
      "Index: datetime64\n",
      "\n",
      "UNIQUE VALUES\n",
      "total_ice_sheet_mass_change    248\n",
      "dtype: int64\n",
      "\n",
      "NULL VALUES\n",
      "Total null rows: 0\n",
      "Percentage null rows: 0.0%\n",
      "\n",
      "DUPLICATES\n",
      "Total duplicate rows: 0\n",
      "Percentage duplicate rows: 0.0%\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep.basic_eda(df_ice_sheets_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_ice_sheet_mass_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-04-30</th>\n",
       "      <td>27.303182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-31</th>\n",
       "      <td>49.320792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-06-30</th>\n",
       "      <td>-56.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-07-31</th>\n",
       "      <td>-169.678182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-08-31</th>\n",
       "      <td>-257.390352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            total_ice_sheet_mass_change\n",
       "2002-04-30                    27.303182\n",
       "2002-05-31                    49.320792\n",
       "2002-06-30                   -56.745000\n",
       "2002-07-31                  -169.678182\n",
       "2002-08-31                  -257.390352"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ice_sheets_resampled.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Mean Sea Level"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Inspection - Global Mean Sea Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE\n",
      "Rows: 1152 \t Columns: 1\n",
      "\n",
      "DATATYPES\n",
      "Columns: \n",
      "HDR Global Mean Sea Level Data    object\n",
      "dtype: object\n",
      "Index: integer\n",
      "\n",
      "UNIQUE VALUES\n",
      "HDR Global Mean Sea Level Data    1143\n",
      "dtype: int64\n",
      "\n",
      "NULL VALUES\n",
      "Total null rows: 0\n",
      "Percentage null rows: 0.0%\n",
      "\n",
      "DUPLICATES\n",
      "Total duplicate rows: 11\n",
      "Percentage duplicate rows: 0.95%\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep.basic_eda(df_sea_level_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HDR Global Mean Sea Level Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HDR This file contains Global Mean Sea Level (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HDR auspices of the NASA Sea Level Change prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HDR Climate Research (http://podaac.jpl.nasa.g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDR TOPEX/Poseidon, Jason-1, OSTM/Jason-2, Jas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      HDR Global Mean Sea Level Data\n",
       "0                                                HDR\n",
       "1  HDR This file contains Global Mean Sea Level (...\n",
       "2  HDR auspices of the NASA Sea Level Change prog...\n",
       "3  HDR Climate Research (http://podaac.jpl.nasa.g...\n",
       "4  HDR TOPEX/Poseidon, Jason-1, OSTM/Jason-2, Jas..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sea_level_raw.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations\n",
    "- Readings are taken at non-uniform intervals.\n",
    "- No clear date that readings are relative to.\n",
    "- There is a lot of unnecessary data in the dataset. I will only want to keep `GMSL` and `year+fraction_of_year`.\n",
    "- Date is given as a decimal.\n",
    "- `GMSL` is currently an object datatype."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning - Global Mean Sea Level"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Cleaning Steps:\n",
    "- Remove all text at the head of the file.\n",
    "- Split the data in to multiple columns.\n",
    "- Rename columns.\n",
    "- Drop unnecessary columns.\n",
    "- Convert `year+fraction_of_year` to datetime `Date` column.\n",
    "- Set `Date` as index.\n",
    "- Convert `GMSL` to float.\n",
    "- Expand index to include all missing dates.\n",
    "- Interpolate data to fill added dates.\n",
    "- Set `GMSL` for first entry to 0 and all other entries relative to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all text rows and reset index.\n",
    "df_sea_level_raw = df_sea_level_raw[df_sea_level_raw.iloc[:,0].str.startswith('HDR')==False].reset_index(drop=True)\n",
    "\n",
    "# Rename header.\n",
    "df_sea_level_raw.columns = ['0'] \n",
    "\n",
    "# Append space to allow for easier delimitation and split columns.\n",
    "df_sea_level_raw['0'] = ' ' + df_sea_level_raw['0'] \n",
    "df_sea_level_raw = df_sea_level_raw.iloc[:,0].str.split(' +',expand=True, regex=True)\n",
    "\n",
    "# Remove first column and rename remaining columns.\n",
    "df_sea_level_raw = df_sea_level_raw.iloc[:,1:] \n",
    "df_sea_level_raw = df_sea_level_raw.rename({1:'altimeter_type',\n",
    "                                            2:'merged_file_cycle',\n",
    "                                            3:'year+fraction_of_year',\n",
    "                                            4:'no_observations',\n",
    "                                            5:'no_weighted_obs',\n",
    "                                            6:'GMSL',\n",
    "                                            7:'STD_DEV',\n",
    "                                            8:'smoothed_GMSL',\n",
    "                                            9:'GMSL_variatiion',\n",
    "                                            10:'std_dev_GMSL_variation',\n",
    "                                            11:'smoothed_GMSL_variation',\n",
    "                                            12:'smoothed_GMSL_variation_signal_rem'},axis='columns')\n",
    "\n",
    "# Convert dates to caldendar date and set as index.\n",
    "df_sea_level_raw['Date'] = \\\n",
    "    pd.to_datetime([prep.decimal_to_datetime(date) for date in df_sea_level_raw['year+fraction_of_year'].astype(float).tolist()])\n",
    "df_sea_level_raw.set_index('Date', inplace=True)\n",
    "\n",
    "# Filter GMSL and set as float.\n",
    "df_sea_level_raw = df_sea_level_raw[['GMSL']]\n",
    "df_sea_level_raw[['GMSL']] = df_sea_level_raw[['GMSL']].astype(float)\n",
    "\n",
    "# Reindex the dataframe to include the missing dates and interpolate new values.\n",
    "df_sea_level_raw = df_sea_level_raw.reindex(pd.date_range(df_sea_level_raw.index[0],df_sea_level_raw.index[-1]))\n",
    "df_sea_level_raw['GMSL'] = df_sea_level_raw['GMSL'].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample timeseries to match required length.\n",
    "df_sea_level_resampled = prep.resample_timeseries(df_sea_level_raw)\n",
    "\n",
    "# Adjust GMSL to be relative to start of sampling period.\n",
    "df_sea_level_resampled['GMSL'] = round(df_sea_level_resampled['GMSL'] + abs(df_sea_level_resampled['GMSL'][0]),2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review - Global Mean Sea Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE\n",
      "Rows: 248 \t Columns: 1\n",
      "\n",
      "DATATYPES\n",
      "Columns: \n",
      "GMSL    float64\n",
      "dtype: object\n",
      "Index: datetime64\n",
      "\n",
      "UNIQUE VALUES\n",
      "GMSL    246\n",
      "dtype: int64\n",
      "\n",
      "NULL VALUES\n",
      "Total null rows: 0\n",
      "Percentage null rows: 0.0%\n",
      "\n",
      "DUPLICATES\n",
      "Total duplicate rows: 4\n",
      "Percentage duplicate rows: 1.61%\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep.basic_eda(df_sea_level_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GMSL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-04-30</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-31</th>\n",
       "      <td>-1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-06-30</th>\n",
       "      <td>-1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-07-31</th>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-08-31</th>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GMSL\n",
       "2002-04-30  0.00\n",
       "2002-05-31 -1.34\n",
       "2002-06-30 -1.69\n",
       "2002-07-31  3.42\n",
       "2002-08-31  8.99"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sea_level_resampled.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sea Temperature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Inspection - Sea Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE\n",
      "Rows: 2077 \t Columns: 10\n",
      "\n",
      "DATATYPES\n",
      "Columns: \n",
      "year                                          int64\n",
      "month                                         int64\n",
      "anomaly                                     float64\n",
      "total_uncertainty                           float64\n",
      "uncorrelated_uncertainty                    float64\n",
      "correlated_uncertainty                      float64\n",
      "bias_uncertainty                            float64\n",
      "coverage_uncertainty                        float64\n",
      "lower_bound_95pct_bias_uncertainty_range    float64\n",
      "upper_bound_95pct_bias_uncertainty_range    float64\n",
      "dtype: object\n",
      "Index: integer\n",
      "\n",
      "UNIQUE VALUES\n",
      "year                                         174\n",
      "month                                         12\n",
      "anomaly                                     2051\n",
      "total_uncertainty                           1796\n",
      "uncorrelated_uncertainty                    1226\n",
      "correlated_uncertainty                      1691\n",
      "bias_uncertainty                            1409\n",
      "coverage_uncertainty                        1758\n",
      "lower_bound_95pct_bias_uncertainty_range    1368\n",
      "upper_bound_95pct_bias_uncertainty_range    1382\n",
      "dtype: int64\n",
      "\n",
      "NULL VALUES\n",
      "Total null rows: 0\n",
      "Percentage null rows: 0.0%\n",
      "\n",
      "DUPLICATES\n",
      "Total duplicate rows: 0\n",
      "Percentage duplicate rows: 0.0%\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep.basic_eda(df_sea_temp_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>total_uncertainty</th>\n",
       "      <th>uncorrelated_uncertainty</th>\n",
       "      <th>correlated_uncertainty</th>\n",
       "      <th>bias_uncertainty</th>\n",
       "      <th>coverage_uncertainty</th>\n",
       "      <th>lower_bound_95pct_bias_uncertainty_range</th>\n",
       "      <th>upper_bound_95pct_bias_uncertainty_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1850</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.35138</td>\n",
       "      <td>0.14007</td>\n",
       "      <td>0.03096</td>\n",
       "      <td>0.09622</td>\n",
       "      <td>0.04578</td>\n",
       "      <td>0.08547</td>\n",
       "      <td>-0.4530</td>\n",
       "      <td>-0.2695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1850</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.34437</td>\n",
       "      <td>0.13852</td>\n",
       "      <td>0.03158</td>\n",
       "      <td>0.09198</td>\n",
       "      <td>0.04642</td>\n",
       "      <td>0.08703</td>\n",
       "      <td>-0.4475</td>\n",
       "      <td>-0.2615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1850</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.58001</td>\n",
       "      <td>0.15060</td>\n",
       "      <td>0.03537</td>\n",
       "      <td>0.09765</td>\n",
       "      <td>0.04425</td>\n",
       "      <td>0.09968</td>\n",
       "      <td>-0.6780</td>\n",
       "      <td>-0.5005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1850</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.34222</td>\n",
       "      <td>0.13522</td>\n",
       "      <td>0.03352</td>\n",
       "      <td>0.09939</td>\n",
       "      <td>0.04384</td>\n",
       "      <td>0.07322</td>\n",
       "      <td>-0.4390</td>\n",
       "      <td>-0.2630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1850</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.25093</td>\n",
       "      <td>0.12226</td>\n",
       "      <td>0.03314</td>\n",
       "      <td>0.09200</td>\n",
       "      <td>0.03897</td>\n",
       "      <td>0.06218</td>\n",
       "      <td>-0.3375</td>\n",
       "      <td>-0.1810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  anomaly  total_uncertainty  uncorrelated_uncertainty  \\\n",
       "0  1850      1 -0.35138            0.14007                   0.03096   \n",
       "1  1850      2 -0.34437            0.13852                   0.03158   \n",
       "2  1850      3 -0.58001            0.15060                   0.03537   \n",
       "3  1850      4 -0.34222            0.13522                   0.03352   \n",
       "4  1850      5 -0.25093            0.12226                   0.03314   \n",
       "\n",
       "   correlated_uncertainty  bias_uncertainty  coverage_uncertainty  \\\n",
       "0                 0.09622           0.04578               0.08547   \n",
       "1                 0.09198           0.04642               0.08703   \n",
       "2                 0.09765           0.04425               0.09968   \n",
       "3                 0.09939           0.04384               0.07322   \n",
       "4                 0.09200           0.03897               0.06218   \n",
       "\n",
       "   lower_bound_95pct_bias_uncertainty_range  \\\n",
       "0                                   -0.4530   \n",
       "1                                   -0.4475   \n",
       "2                                   -0.6780   \n",
       "3                                   -0.4390   \n",
       "4                                   -0.3375   \n",
       "\n",
       "   upper_bound_95pct_bias_uncertainty_range  \n",
       "0                                   -0.2695  \n",
       "1                                   -0.2615  \n",
       "2                                   -0.5005  \n",
       "3                                   -0.2630  \n",
       "4                                   -0.1810  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sea_temp_raw.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- There are a lot of different metrics given. I'll only need the date and the anomaly data for my analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning - Sea Temperature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Steps:\n",
    "- Remove unnecessary columns.\n",
    "- Create date column and set as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract useful columns.\n",
    "df_sea_temp_raw = df_sea_temp_raw[['year','month','anomaly']]\n",
    "\n",
    "# Create date column and set as index.\n",
    "df_sea_temp_raw['Date'] = \\\n",
    "    pd.to_datetime(dict(year=df_sea_temp_raw['year'],month=df_sea_temp_raw['month'], day=1)) + pd.offsets.MonthEnd()\n",
    "df_sea_temp_raw.drop(['year','month'],axis=1,inplace=True)\n",
    "df_sea_temp_raw.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample timeseries to match required length.\n",
    "df_sea_temp_resampled = prep.resample_timeseries(df_sea_temp_raw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review - Sea Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE\n",
      "Rows: 248 \t Columns: 1\n",
      "\n",
      "DATATYPES\n",
      "Columns: \n",
      "anomaly    float64\n",
      "dtype: object\n",
      "Index: datetime64\n",
      "\n",
      "UNIQUE VALUES\n",
      "anomaly    247\n",
      "dtype: int64\n",
      "\n",
      "NULL VALUES\n",
      "Total null rows: 0\n",
      "Percentage null rows: 0.0%\n",
      "\n",
      "DUPLICATES\n",
      "Total duplicate rows: 2\n",
      "Percentage duplicate rows: 0.81%\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep.basic_eda(df_sea_temp_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-04-30</th>\n",
       "      <td>0.45826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-31</th>\n",
       "      <td>0.46104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-06-30</th>\n",
       "      <td>0.46607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-07-31</th>\n",
       "      <td>0.41203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-08-31</th>\n",
       "      <td>0.43217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            anomaly\n",
       "Date               \n",
       "2002-04-30  0.45826\n",
       "2002-05-31  0.46104\n",
       "2002-06-30  0.46607\n",
       "2002-07-31  0.41203\n",
       "2002-08-31  0.43217"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sea_temp_resampled.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(248, 1)\n",
      "(248, 1)\n",
      "(248, 1)\n",
      "(248, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check shape of all data frames.\n",
    "frames = [df_sea_ice_resampled,df_sea_temp_resampled,df_sea_level_resampled,df_ice_sheets_resampled]\n",
    "\n",
    "for frame in frames:\n",
    "    print(frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes.\n",
    "earth_vitals_df = pd.concat([df_sea_ice_resampled, df_sea_temp_resampled, \\\n",
    "                             df_ice_sheets_resampled,df_sea_level_resampled], axis=1)\n",
    "\n",
    "# Rename columns.\n",
    "earth_vitals_df.rename(columns={'global_sea_ice_extent':'global_sea_ice_extent',\n",
    "                                'anomaly':'sea_temp_anomaly',\n",
    "                                'total_ice_sheet_mass_loss':'total_ice_sheet_mass_loss',\n",
    "                                'GMSL':'global_mean_sea_level'\n",
    "                                }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE\n",
      "Rows: 248 \t Columns: 4\n",
      "\n",
      "DATATYPES\n",
      "Columns: \n",
      "global_sea_ice_extent          float64\n",
      "sea_temp_anomaly               float64\n",
      "total_ice_sheet_mass_change    float64\n",
      "global_mean_sea_level          float64\n",
      "dtype: object\n",
      "Index: datetime64\n",
      "\n",
      "UNIQUE VALUES\n",
      "global_sea_ice_extent          248\n",
      "sea_temp_anomaly               247\n",
      "total_ice_sheet_mass_change    248\n",
      "global_mean_sea_level          246\n",
      "dtype: int64\n",
      "\n",
      "NULL VALUES\n",
      "Total null rows: 0\n",
      "Percentage null rows: 0.0%\n",
      "\n",
      "DUPLICATES\n",
      "Total duplicate rows: 0\n",
      "Percentage duplicate rows: 0.0%\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep.basic_eda(earth_vitals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_sea_ice_extent</th>\n",
       "      <th>sea_temp_anomaly</th>\n",
       "      <th>total_ice_sheet_mass_change</th>\n",
       "      <th>global_mean_sea_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-04-30</th>\n",
       "      <td>20.627267</td>\n",
       "      <td>0.45826</td>\n",
       "      <td>27.303182</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-31</th>\n",
       "      <td>22.482161</td>\n",
       "      <td>0.46104</td>\n",
       "      <td>49.320792</td>\n",
       "      <td>-1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-06-30</th>\n",
       "      <td>23.959167</td>\n",
       "      <td>0.46607</td>\n",
       "      <td>-56.745000</td>\n",
       "      <td>-1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-07-31</th>\n",
       "      <td>24.688871</td>\n",
       "      <td>0.41203</td>\n",
       "      <td>-169.678182</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-08-31</th>\n",
       "      <td>23.665677</td>\n",
       "      <td>0.43217</td>\n",
       "      <td>-257.390352</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            global_sea_ice_extent  sea_temp_anomaly  \\\n",
       "2002-04-30              20.627267           0.45826   \n",
       "2002-05-31              22.482161           0.46104   \n",
       "2002-06-30              23.959167           0.46607   \n",
       "2002-07-31              24.688871           0.41203   \n",
       "2002-08-31              23.665677           0.43217   \n",
       "\n",
       "            total_ice_sheet_mass_change  global_mean_sea_level  \n",
       "2002-04-30                    27.303182                   0.00  \n",
       "2002-05-31                    49.320792                  -1.34  \n",
       "2002-06-30                   -56.745000                  -1.69  \n",
       "2002-07-31                  -169.678182                   3.42  \n",
       "2002-08-31                  -257.390352                   8.99  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earth_vitals_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Clean CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "earth_vitals_df.to_csv('../data/cleaned/earth_vitals.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09e0667df48662ba59e926db1e739031b5dcfd853ec9e245668fd4ef9b75a44c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
